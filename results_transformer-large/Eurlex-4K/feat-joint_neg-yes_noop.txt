Namespace(ensemble=True, input_inst_label='datasets/Eurlex-4K/Y.tst.npz', pred_path=['pretrained_models/Eurlex-4K/pifa-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz', 'pretrained_models/Eurlex-4K/pifa-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz', 'pretrained_models/Eurlex-4K/pifa-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz', 'pretrained_models/Eurlex-4K/pifa-neural-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz', 'pretrained_models/Eurlex-4K/pifa-neural-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz', 'pretrained_models/Eurlex-4K/pifa-neural-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz', 'pretrained_models/Eurlex-4K/text-emb-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz', 'pretrained_models/Eurlex-4K/text-emb-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz', 'pretrained_models/Eurlex-4K/text-emb-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz'])
==== Evaluation on pretrained_models/Eurlex-4K/pifa-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz
prec   = 85.07 79.03 72.94 66.84 60.83 55.42 50.16 45.74 41.84 38.48
recall = 17.20 31.73 43.45 52.47 59.17 64.31 67.67 70.31 72.21 73.64
==== Evaluation on pretrained_models/Eurlex-4K/pifa-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz
prec   = 85.02 78.87 73.08 67.01 61.20 55.50 50.21 45.82 42.07 38.78
recall = 17.26 31.68 43.52 52.65 59.53 64.36 67.62 70.31 72.49 74.11
==== Evaluation on pretrained_models/Eurlex-4K/pifa-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz
prec   = 85.49 78.75 72.41 66.50 60.48 55.11 50.02 45.45 41.75 38.47
recall = 17.30 31.66 43.11 52.18 58.80 63.87 67.34 69.78 71.93 73.54
==== Evaluation on pretrained_models/Eurlex-4K/pifa-neural-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz
prec   = 85.10 79.12 73.09 66.98 61.06 55.22 50.04 45.59 41.77 38.48
recall = 17.29 31.80 43.52 52.54 59.34 64.01 67.41 69.96 71.98 73.52
==== Evaluation on pretrained_models/Eurlex-4K/pifa-neural-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz
prec   = 85.49 79.08 73.09 67.28 61.10 55.59 50.37 45.87 42.13 38.85
recall = 17.30 31.71 43.43 52.78 59.35 64.46 67.85 70.38 72.60 74.28
==== Evaluation on pretrained_models/Eurlex-4K/pifa-neural-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz
prec   = 84.58 78.86 72.76 66.73 60.60 55.26 50.24 45.78 41.83 38.60
recall = 17.16 31.66 43.27 52.33 58.92 64.05 67.65 70.23 72.05 73.74
==== Evaluation on pretrained_models/Eurlex-4K/text-emb-a5-s0/ranker_bert-large-cased-whole-word-masking_seq-128/tst.pred.npz
prec   = 86.60 79.37 72.86 66.60 60.16 54.35 49.03 44.40 40.50 37.06
recall = 17.55 31.80 43.36 52.28 58.47 63.02 66.04 68.19 69.83 70.91
==== Evaluation on pretrained_models/Eurlex-4K/text-emb-a5-s0/ranker_roberta-large_seq-128/tst.pred.npz
prec   = 86.65 80.13 73.89 67.74 61.38 55.48 50.02 45.32 41.22 37.79
recall = 17.56 32.16 43.97 53.17 59.71 64.32 67.42 69.60 71.09 72.28
==== Evaluation on pretrained_models/Eurlex-4K/text-emb-a5-s0/ranker_xlnet-large-cased_seq-128/tst.pred.npz
prec   = 86.96 80.09 73.21 66.61 60.35 54.43 49.01 44.45 40.47 37.07
recall = 17.58 32.08 43.48 52.25 58.68 63.08 65.99 68.23 69.76 70.90
==== Evaluations of Ensembles of All Predictions ====
ens: average
prec   = 87.66 81.29 75.13 69.01 62.87 57.22 51.98 47.50 43.52 40.08
recall = 17.75 32.68 44.77 54.19 61.13 66.31 69.97 72.82 74.92 76.57
ens: rank_average
prec   = 87.66 81.32 75.23 68.91 62.95 57.33 52.12 47.57 43.57 40.14
recall = 17.75 32.68 44.83 54.09 61.21 66.42 70.13 72.93 75.03 76.69
ens: round_robin
prec   = 85.07 78.98 73.30 67.21 61.43 56.08 51.01 46.60 42.71 39.43
recall = 17.20 31.77 43.66 52.74 59.75 65.01 68.71 71.53 73.61 75.36
